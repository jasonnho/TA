{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 06 — Training v3 (Architecture Alignment + Augmented Data)\n\nPerbaikan arsitektur sesuai paper Wang et al. (2021):\n1. **Cross-Attention ASD** — h_ae attend ke h_sl dengan relative position encoding (Eq. 7-9)\n2. **Prior Embedding** — Word frequency distribution sebagai prior knowledge untuk ATE (Sec. 3.1.4)\n3. **Sentiment Connection** — Pre-train SLD, lalu copy weights ke ASD classifier (Sec. 3.1.5)\n\n| Setting | v1 (Baseline) | v2 (Hyp. Tuning) | v3 (Paper-aligned) |\n|---|---|---|---|\n| Data | 2,451 | 2,451 | **Augmented (5,000)** |\n| Architecture | Self-attention | Self-attention | **Cross-attention + Prior + Sent.Conn.** |\n| Dropout | 0.1 | 0.3 | **0.2** |\n| Weight Decay | 0.01 | 0.05 | **0.03** |\n| Freeze Layers | 0/24 | 18/24 | **12/24** |\n| Early Stopping | Tidak | patience=5 | **patience=5** |\n| ASD Class Weight | Tidak | Ya | **Ya** |\n| Loss Weighting | Sum (1:1:1:1) | Sum | **Paper: λ1=0.3, λ2=0.3** |\n| Best F1 | 0.7263 | 0.7027 | ? |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import string\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer, get_linear_schedule_with_warmup\n",
    "from torchcrf import CRF\n",
    "from seqeval.metrics import classification_report, f1_score as seq_f1_score\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style='whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "print(f'Device: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. KONFIGURASI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Paths\nBASE_DIR = os.path.dirname(os.getcwd())\nDATA_RAW_DIR = os.path.join(BASE_DIR, 'data', 'raw')\nDATA_PROC_DIR = os.path.join(BASE_DIR, 'data', 'processed')\nMODEL_DIR = os.path.join(BASE_DIR, 'models')\nos.makedirs(MODEL_DIR, exist_ok=True)\n\n# USE AUGMENTED DATA\nBIEOS_PATH = os.path.join(DATA_PROC_DIR, 'train_data_bieos_augmented.json')\nPOS_LEX_PATH = os.path.join(DATA_RAW_DIR, 'indonesian_sentiment_lexicon_positive.tsv')\nNEG_LEX_PATH = os.path.join(DATA_RAW_DIR, 'indonesian_sentiment_lexicon_negative.tsv')\n\n# Model\nMODEL_NAME = 'indobenchmark/indobert-large-p2'\nMAX_LENGTH = 128\nPROJ_DIM = 256\n\n# Training — MODERATE (between v1 and v2)\nBATCH_SIZE = 4\nGRADIENT_ACCUMULATION = 4  # effective batch = 16\nNUM_EPOCHS = 30\nLR_BERT = 2e-5\nLR_HEAD = 1e-4\nWARMUP_RATIO = 0.1\nWEIGHT_DECAY = 0.03        # v1: 0.01, v2: 0.05 -> v3: 0.03\nMAX_GRAD_NORM = 1.0\nTRAIN_RATIO = 0.85\nSEED = 42\n\n# Moderate regularization\nDROPOUT = 0.2              # v1: 0.1, v2: 0.3 -> v3: 0.2\nFREEZE_LAYERS = 12         # v1: 0, v2: 18 -> v3: 12 (freeze 50%)\nEARLY_STOP_PATIENCE = 5\n\n# Architecture (Paper-aligned)\nPHASE1_EPOCHS = 3           # SLD pre-training for Sentiment Connection\nLAMBDA1 = 0.3               # Paper Eq. 10: weight for L_ae + L_sl\nLAMBDA2 = 0.3               # Paper Eq. 10: weight for L_sd\nMAX_REL_POS = 20            # Max relative position for cross-attention\n\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(SEED)\n\nprint(f'Model       : {MODEL_NAME}')\nprint(f'Data        : AUGMENTED')\nprint(f'Batch size  : {BATCH_SIZE} x {GRADIENT_ACCUMULATION} accum = {BATCH_SIZE * GRADIENT_ACCUMULATION} effective')\nprint(f'Training    : Phase 1 ({PHASE1_EPOCHS} epochs) + Phase 2 (max {NUM_EPOCHS} epochs)')\nprint(f'LR (BERT)   : {LR_BERT}')\nprint(f'LR (heads)  : {LR_HEAD}')\nprint(f'Weight decay: {WEIGHT_DECAY}')\nprint(f'Dropout     : {DROPOUT}')\nprint(f'Freeze BERT : {FREEZE_LAYERS}/24 layers')\nprint(f'Loss weight : λ1={LAMBDA1}, λ2={LAMBDA2} (paper Eq. 10)')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AUGMENTED BIEOS data\n",
    "with open(BIEOS_PATH, 'r', encoding='utf-8') as f:\n",
    "    raw_data = json.load(f)\n",
    "print(f'Total data (augmented): {len(raw_data)}')\n",
    "\n",
    "# Load sentiment lexicon\n",
    "def load_lexicon(path):\n",
    "    words = set()\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        next(f)  # skip header\n",
    "        for line in f:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if parts:\n",
    "                word = parts[0].strip().lower()\n",
    "                if ' ' not in word and len(word) > 1:\n",
    "                    words.add(word)\n",
    "    return words\n",
    "\n",
    "pos_lexicon = load_lexicon(POS_LEX_PATH)\n",
    "neg_lexicon = load_lexicon(NEG_LEX_PATH)\n",
    "\n",
    "overlap = pos_lexicon & neg_lexicon\n",
    "pos_lexicon -= overlap\n",
    "neg_lexicon -= overlap\n",
    "\n",
    "print(f'Positive lexicon : {len(pos_lexicon)} words')\n",
    "print(f'Negative lexicon : {len(neg_lexicon)} words')\n",
    "print(f'Overlap removed  : {len(overlap)} words')\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "print(f'Tokenizer loaded : {MODEL_NAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. MULTI-TASK LABEL PREPARATION\n",
    "\n",
    "| Task | Label Scheme | Jumlah |\n",
    "|---|---|---|\n",
    "| **ATE** (Aspect Term Extraction) | O, B, I, E, S | 5 |\n",
    "| **SLD** (Sentiment Lexicon Detection) | O, POS, NEG | 3 |\n",
    "| **ASD** (Aspect Sentiment Detection) | O, POS, NEG, NEU | 4 |\n",
    "| **Final** (Aspect Polarity - CRF) | O, B/I/E/S-POS/NEG/NEU | 13 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Label schemes\nate_labels = ['O', 'B', 'I', 'E', 'S']\nsld_labels = ['O', 'POS', 'NEG']\nasd_labels = ['O', 'POS', 'NEG', 'NEU']\nbieos_labels = ['O', 'B-NEG', 'B-NEU', 'B-POS', 'E-NEG', 'E-NEU', 'E-POS',\n                'I-NEG', 'I-NEU', 'I-POS', 'S-NEG', 'S-NEU', 'S-POS']\n\nate_label2id = {l: i for i, l in enumerate(ate_labels)}\nsld_label2id = {l: i for i, l in enumerate(sld_labels)}\nasd_label2id = {l: i for i, l in enumerate(asd_labels)}\nbieos_label2id = {l: i for i, l in enumerate(bieos_labels)}\nbieos_id2label = {i: l for l, i in bieos_label2id.items()}\n\nIGNORE_INDEX = -100\n\n# --- Prior Embedding: word-level ATE frequency distribution (Paper Sec. 3.1.4) ---\nword_ate_freq = {}\nfor d in raw_data:\n    for tok, lab in zip(d['tokens'], d['labels']):\n        tok_lower = tok.lower()\n        if tok_lower not in word_ate_freq:\n            word_ate_freq[tok_lower] = [0] * len(ate_labels)\n        if lab == 'O':\n            word_ate_freq[tok_lower][ate_label2id['O']] += 1\n        else:\n            prefix = lab.split('-')[0]\n            word_ate_freq[tok_lower][ate_label2id[prefix]] += 1\n\n# Normalize to probability distribution per word\ndefault_prior = [1.0] + [0.0] * (len(ate_labels) - 1)  # default: 100% O\nword_prior = {}\nfor word, counts in word_ate_freq.items():\n    total = sum(counts)\n    word_prior[word] = [c / total for c in counts] if total > 0 else default_prior\n\nprint(f'Prior vocabulary: {len(word_prior)} unique words')\naspect_words = [(w, p) for w, p in word_prior.items() if p[0] < 0.5]\naspect_words.sort(key=lambda x: x[1][0])\nprint('Top aspect-heavy words (low O probability):')\nfor w, p in aspect_words[:5]:\n    labels_str = ' '.join(f'{ate_labels[i]}={p[i]:.2f}' for i in range(len(ate_labels)))\n    print(f'  \"{w}\": {labels_str}')\n\n# --- Prepare aligned labels for all 4 tasks + prior probs ---\nall_input_ids = []\nall_attention_mask = []\nall_ate = []\nall_sld = []\nall_asd = []\nall_bieos = []\nall_crf = []\nall_prior = []\n\nfor d in tqdm(raw_data, desc='Preparing labels'):\n    tokens, labels = d['tokens'], d['labels']\n\n    enc = tokenizer(tokens, is_split_into_words=True,\n                    max_length=MAX_LENGTH, padding='max_length',\n                    truncation=True, return_tensors='pt')\n    word_ids = enc.word_ids(batch_index=0)\n\n    # Word-level labels\n    ate_w, sld_w, asd_w = [], [], []\n    for tok, lab in zip(tokens, labels):\n        if lab == 'O':\n            ate_w.append('O'); asd_w.append('O')\n        else:\n            prefix, sentiment = lab.split('-', 1)\n            ate_w.append(prefix); asd_w.append(sentiment)\n\n        t_clean = tok.lower().strip(string.punctuation)\n        if t_clean in pos_lexicon:\n            sld_w.append('POS')\n        elif t_clean in neg_lexicon:\n            sld_w.append('NEG')\n        else:\n            sld_w.append('O')\n\n    # Align to subword positions\n    ate_a, sld_a, asd_a, bieos_a, crf_a, prior_a = [], [], [], [], [], []\n    prev_wid = None\n    for wid in word_ids:\n        if wid is None:\n            ate_a.append(IGNORE_INDEX)\n            sld_a.append(IGNORE_INDEX)\n            asd_a.append(IGNORE_INDEX)\n            bieos_a.append(IGNORE_INDEX)\n            crf_a.append(0)\n            prior_a.append(default_prior)\n        elif wid != prev_wid:\n            if wid < len(tokens):\n                ate_a.append(ate_label2id[ate_w[wid]])\n                sld_a.append(sld_label2id[sld_w[wid]])\n                asd_a.append(asd_label2id[asd_w[wid]])\n                bieos_a.append(bieos_label2id[labels[wid]])\n                crf_a.append(bieos_label2id[labels[wid]])\n                prior_a.append(word_prior.get(tokens[wid].lower(), default_prior))\n            else:\n                ate_a.append(IGNORE_INDEX); sld_a.append(IGNORE_INDEX)\n                asd_a.append(IGNORE_INDEX); bieos_a.append(IGNORE_INDEX)\n                crf_a.append(0)\n                prior_a.append(default_prior)\n        else:\n            ate_a.append(IGNORE_INDEX); sld_a.append(IGNORE_INDEX)\n            asd_a.append(IGNORE_INDEX); bieos_a.append(IGNORE_INDEX)\n            crf_a.append(bieos_label2id[labels[wid]] if wid < len(tokens) else 0)\n            prior_a.append(word_prior.get(tokens[wid].lower(), default_prior) if wid < len(tokens) else default_prior)\n        prev_wid = wid\n\n    all_input_ids.append(enc['input_ids'].squeeze(0))\n    all_attention_mask.append(enc['attention_mask'].squeeze(0))\n    all_ate.append(torch.tensor(ate_a, dtype=torch.long))\n    all_sld.append(torch.tensor(sld_a, dtype=torch.long))\n    all_asd.append(torch.tensor(asd_a, dtype=torch.long))\n    all_bieos.append(torch.tensor(bieos_a, dtype=torch.long))\n    all_crf.append(torch.tensor(crf_a, dtype=torch.long))\n    all_prior.append(torch.tensor(prior_a, dtype=torch.float))\n\ndata_dict = {\n    'input_ids': torch.stack(all_input_ids),\n    'attention_mask': torch.stack(all_attention_mask),\n    'ate_labels': torch.stack(all_ate),\n    'sld_labels': torch.stack(all_sld),\n    'asd_labels': torch.stack(all_asd),\n    'bieos_labels': torch.stack(all_bieos),\n    'crf_labels': torch.stack(all_crf),\n    'prior_probs': torch.stack(all_prior),\n}\n\nprint('\\nDataset shapes:')\nfor k, v in data_dict.items():\n    print(f'  {k}: {v.shape}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. DATASET & DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ABSAMultiTaskDataset(Dataset):\n",
    "    def __init__(self, data_dict, indices):\n",
    "        self.data = {k: v[indices] for k, v in data_dict.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data['input_ids'].size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {k: v[idx] for k, v in self.data.items()}\n",
    "\n",
    "# Train/Val split\n",
    "total = len(raw_data)\n",
    "indices = torch.randperm(total, generator=torch.Generator().manual_seed(SEED))\n",
    "split = int(total * TRAIN_RATIO)\n",
    "\n",
    "train_dataset = ABSAMultiTaskDataset(data_dict, indices[:split])\n",
    "val_dataset = ABSAMultiTaskDataset(data_dict, indices[split:])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE * 2)\n",
    "\n",
    "print(f'Train: {len(train_dataset)} ({TRAIN_RATIO*100:.0f}%)')\n",
    "print(f'Val  : {len(val_dataset)} ({(1-TRAIN_RATIO)*100:.0f}%)')\n",
    "print(f'Train batches: {len(train_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. COMPUTE CLASS WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights for ASD task from training data\n",
    "train_asd = train_dataset.data['asd_labels'].flatten()\n",
    "train_asd_valid = train_asd[train_asd != IGNORE_INDEX]\n",
    "asd_counts = Counter(train_asd_valid.tolist())\n",
    "\n",
    "print('ASD label distribution (train):')\n",
    "for lid in range(len(asd_labels)):\n",
    "    print(f'  {asd_labels[lid]:4s}: {asd_counts.get(lid, 0)}')\n",
    "\n",
    "total_asd = sum(asd_counts.values())\n",
    "n_classes = len(asd_labels)\n",
    "asd_weights = torch.zeros(n_classes)\n",
    "for lid in range(n_classes):\n",
    "    count = asd_counts.get(lid, 1)\n",
    "    asd_weights[lid] = total_asd / (n_classes * count)\n",
    "\n",
    "asd_weights = asd_weights / asd_weights.mean()\n",
    "asd_weights = asd_weights.to(device)\n",
    "\n",
    "print(f'\\nASD class weights:')\n",
    "for lid in range(n_classes):\n",
    "    print(f'  {asd_labels[lid]:4s}: {asd_weights[lid]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 6. MODEL ARCHITECTURE (Paper-aligned)\n\nSesuai Wang et al. (2021), adaptasi: IndoBERT menggantikan BiLSTM sebagai encoder.\n\n**Perubahan dari v1/v2:**\n1. **Prior Embedding** — word frequency prior ditambahkan ke input ATE (Sec. 3.1.4)\n2. **Cross-Attention ASD** — h_ae attend ke h_sl dengan relative position encoding (Eq. 7-9)\n3. **Sentiment Connection** — SLD classifier weights → ASD classifier (Sec. 3.1.5)\n4. **Loss Weighting** — λ1=0.3 (ATE+SLD), λ2=0.3 (ASD), 1.0 (CRF) sesuai Eq. 10\n\n```\nIndoBERT (shared encoder, top 12 layers trainable)\n        |\n        h\n       / \\\n  [h;prior] h\n      |      |\n    h_ae   h_sl\n     |       |\n  ATE cls  SLD cls         ← CE loss (λ1=0.3)\n     |       |\n  CrossAttn(h_ae → h_sl)   ← Paper Eq. 7-9 (with position encoding)\n        |\n       h_sd\n        |\n     ASD cls                ← Weighted CE (λ2=0.3)\n        |\n  [h_ae ; h_sd]\n        |\n      CRF                   ← NLL loss (λ=1.0)\n```\n\n**Sentiment Connection**: Phase 1 (3 epochs) → copy SLD classifier → Phase 2 (main training)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class CrossAttentionASD(nn.Module):\n    \"\"\"Paper Eq. 7-9: Cross-attention from ATE to SLD with relative position encoding.\n\n    s_ij = w_s^T * tanh(W_ae*h_ae_i + W_sl*h_sl_j + W_pos*p_ij + b)\n    a_ij = softmax(s_ij) over j\n    h_sd_i = sum_j(a_ij * h_sl_j)\n    \"\"\"\n\n    def __init__(self, dim, max_relative_position=20):\n        super().__init__()\n        self.max_rel_pos = max_relative_position\n\n        # Relative position embedding: 2k+1 possible values\n        self.pos_embedding = nn.Embedding(2 * max_relative_position + 1, dim)\n\n        # Decomposed scoring (memory-efficient):\n        # W_s * [h_ae; h_sl; p_ij] = W_ae*h_ae + W_sl*h_sl + W_pos*p_ij\n        self.W_ae = nn.Linear(dim, dim, bias=False)\n        self.W_sl = nn.Linear(dim, dim, bias=False)\n        self.W_pos = nn.Linear(dim, dim, bias=False)\n        self.bias = nn.Parameter(torch.zeros(dim))\n        self.w_s = nn.Linear(dim, 1, bias=False)\n\n    def forward(self, h_ae, h_sl, mask=None):\n        \"\"\"\n        h_ae: (batch, seq, dim) - ATE representations (query)\n        h_sl: (batch, seq, dim) - SLD representations (key/value)\n        mask: (batch, seq) - True = valid position\n        Returns: h_sd (batch, seq, dim)\n        \"\"\"\n        batch, seq_len, dim = h_ae.shape\n\n        # Relative position indices: clipped to [-k, k], shifted to [0, 2k]\n        pos = torch.arange(seq_len, device=h_ae.device)\n        rel_pos = (pos.unsqueeze(0) - pos.unsqueeze(1)).clamp(\n            -self.max_rel_pos, self.max_rel_pos) + self.max_rel_pos\n        p_ij = self.pos_embedding(rel_pos)  # (seq, seq, dim)\n\n        # Decomposed: W_ae*h_ae + W_sl*h_sl + W_pos*p_ij + b\n        s_ae = self.W_ae(h_ae)     # (batch, seq, dim)\n        s_sl = self.W_sl(h_sl)     # (batch, seq, dim)\n        s_pos = self.W_pos(p_ij)   # (seq, seq, dim)\n\n        # Broadcasting: (B, seq_i, 1, D) + (B, 1, seq_j, D) + (1, seq_i, seq_j, D)\n        combined = s_ae.unsqueeze(2) + s_sl.unsqueeze(1) + s_pos.unsqueeze(0) + self.bias\n        scores = self.w_s(torch.tanh(combined)).squeeze(-1)  # (batch, seq, seq)\n\n        # Mask padding positions on the key side\n        if mask is not None:\n            scores = scores.masked_fill(~mask.unsqueeze(1), float('-inf'))\n\n        attn_weights = torch.softmax(scores, dim=-1)  # (batch, seq_i, seq_j)\n        h_sd = torch.bmm(attn_weights, h_sl)          # (batch, seq, dim)\n\n        return h_sd\n\n\nclass HierarchicalMultiTaskABSA(nn.Module):\n    def __init__(self, model_name, num_ate, num_sld, num_asd, num_final,\n                 proj_dim=256, dropout=0.2, asd_weights=None,\n                 max_relative_position=20, lambda1=0.3, lambda2=0.3):\n        super().__init__()\n        self.lambda1 = lambda1\n        self.lambda2 = lambda2\n        self.num_sld = num_sld\n        self.num_asd = num_asd\n\n        self.bert = AutoModel.from_pretrained(model_name, use_safetensors=True, low_cpu_mem_usage=True)\n        bert_dim = self.bert.config.hidden_size\n\n        # Task 1: ATE with Prior Embedding (input: bert_dim + num_ate prior dims)\n        self.ate_proj = nn.Sequential(\n            nn.Linear(bert_dim + num_ate, proj_dim), nn.GELU(), nn.Dropout(dropout))\n        self.ate_classifier = nn.Linear(proj_dim, num_ate)\n\n        # Task 2: SLD\n        self.sld_proj = nn.Sequential(\n            nn.Linear(bert_dim, proj_dim), nn.GELU(), nn.Dropout(dropout))\n        self.sld_classifier = nn.Linear(proj_dim, num_sld)\n\n        # Task 3: ASD with Cross-Attention (Paper Eq. 7-9)\n        self.cross_attention = CrossAttentionASD(proj_dim, max_relative_position)\n        self.asd_classifier = nn.Linear(proj_dim, num_asd)\n\n        # Task 4: CRF\n        self.final_proj = nn.Sequential(\n            nn.Linear(proj_dim * 2, proj_dim), nn.GELU(), nn.Dropout(dropout))\n        self.final_emission = nn.Linear(proj_dim, num_final)\n        self.crf = CRF(num_final, batch_first=True)\n\n        self.dropout = nn.Dropout(dropout)\n        self.asd_weights = asd_weights\n\n    def forward(self, input_ids, attention_mask, prior_probs=None,\n                ate_labels=None, sld_labels=None, asd_labels=None, crf_labels=None, **kwargs):\n        h = self.dropout(self.bert(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state)\n\n        # Task 1: ATE with Prior Embedding\n        if prior_probs is not None:\n            h_with_prior = torch.cat([h, prior_probs], dim=-1)\n        else:\n            h_with_prior = torch.cat([h, torch.zeros(*h.shape[:-1], self.ate_classifier.out_features, device=h.device)], dim=-1)\n        h_ae = self.ate_proj(h_with_prior)\n        ate_logits = self.ate_classifier(h_ae)\n\n        # Task 2: SLD\n        h_sl = self.sld_proj(h)\n        sld_logits = self.sld_classifier(h_sl)\n\n        # Task 3: ASD — Cross-Attention (h_ae → h_sl) with position encoding\n        mask = attention_mask.bool()\n        h_sd = self.cross_attention(h_ae, h_sl, mask=mask)\n        asd_logits = self.asd_classifier(h_sd)\n\n        # Task 4: CRF\n        h_concat = torch.cat([h_ae, h_sd], dim=-1)\n        emissions = self.final_emission(self.final_proj(h_concat))\n\n        outputs = {'ate_logits': ate_logits, 'sld_logits': sld_logits,\n                   'asd_logits': asd_logits, 'emissions': emissions}\n\n        if ate_labels is not None:\n            ce = nn.CrossEntropyLoss(ignore_index=IGNORE_INDEX)\n            loss_ate = ce(ate_logits.view(-1, ate_logits.size(-1)), ate_labels.view(-1))\n            loss_sld = ce(sld_logits.view(-1, sld_logits.size(-1)), sld_labels.view(-1))\n\n            ce_asd = nn.CrossEntropyLoss(ignore_index=IGNORE_INDEX, weight=self.asd_weights)\n            loss_asd = ce_asd(asd_logits.view(-1, asd_logits.size(-1)), asd_labels.view(-1))\n\n            loss_crf = -self.crf(emissions.float(), crf_labels, mask=mask, reduction='mean')\n\n            # Paper Eq. 10: L = λ1*(L_ae + L_sl) + λ2*L_sd + L_co\n            outputs['loss'] = self.lambda1 * (loss_ate + loss_sld) + self.lambda2 * loss_asd + loss_crf\n            outputs['losses'] = {\n                'ate': loss_ate.detach(), 'sld': loss_sld.detach(),\n                'asd': loss_asd.detach(), 'crf': loss_crf.detach()}\n\n        return outputs\n\n    def decode(self, emissions, attention_mask):\n        return self.crf.decode(emissions.float(), mask=attention_mask.bool())\n\n    def apply_sentiment_connection(self):\n        \"\"\"Copy SLD classifier weights to ASD classifier (Paper Sec. 3.1.5).\"\"\"\n        with torch.no_grad():\n            # SLD: [O, POS, NEG] (3) -> ASD: [O, POS, NEG, NEU] (4)\n            n_copy = min(self.num_sld, self.num_asd)\n            self.asd_classifier.weight.data[:n_copy].copy_(self.sld_classifier.weight.data[:n_copy])\n            self.asd_classifier.bias.data[:n_copy].copy_(self.sld_classifier.bias.data[:n_copy])\n        print(f'Sentiment Connection: copied SLD -> ASD weights (classes 0-{n_copy-1}: O, POS, NEG)')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "model = HierarchicalMultiTaskABSA(\n    model_name=MODEL_NAME,\n    num_ate=len(ate_labels),\n    num_sld=len(sld_labels),\n    num_asd=len(asd_labels),\n    num_final=len(bieos_labels),\n    proj_dim=PROJ_DIM,\n    dropout=DROPOUT,\n    asd_weights=asd_weights,\n    max_relative_position=MAX_REL_POS,\n    lambda1=LAMBDA1,\n    lambda2=LAMBDA2,\n).to(device)\n\n# Freeze early BERT layers (50%)\nfor param in model.bert.embeddings.parameters():\n    param.requires_grad = False\n\nfor i in range(FREEZE_LAYERS):\n    for param in model.bert.encoder.layer[i].parameters():\n        param.requires_grad = False\n\ntotal_params = sum(p.numel() for p in model.parameters())\ntrainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\nfrozen = total_params - trainable\nprint(f'Total parameters    : {total_params:,}')\nprint(f'Trainable parameters: {trainable:,} ({trainable/total_params*100:.1f}%)')\nprint(f'Frozen parameters   : {frozen:,} ({frozen/total_params*100:.1f}%)')\nprint(f'BERT hidden size    : {model.bert.config.hidden_size}')\nprint(f'\\nFrozen: embeddings + layers 0-{FREEZE_LAYERS-1}')\nprint(f'Trainable: layers {FREEZE_LAYERS}-23 + all task heads')\nprint(f'\\nNew components (vs v1/v2):')\nprint(f'  Cross-Attention ASD : {sum(p.numel() for p in model.cross_attention.parameters()):,} params')\nprint(f'  Prior Embedding     : +{len(ate_labels)} input dims to ATE projection')\nprint(f'  Sentiment Connection: will copy SLD -> ASD after Phase 1')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 7. TRAINING (Two-Phase + Sentiment Connection)\n\n- **Phase 1** (3 epochs): Pre-training — semua task aktif, SLD classifier dilatih\n- **Sentiment Connection**: Copy SLD classifier weights → ASD classifier\n- **Phase 2** (max 30 epochs): Main training dengan early stopping (patience=5)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device, desc='Evaluating'):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds, all_true = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=desc, leave=False):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            total_loss += outputs['loss'].item()\n",
    "\n",
    "            preds = model.decode(outputs['emissions'], batch['attention_mask'])\n",
    "            bieos_lbl = batch['bieos_labels']\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                pred_seq, true_seq = [], []\n",
    "                for j in range(len(preds[i])):\n",
    "                    if bieos_lbl[i][j].item() != IGNORE_INDEX:\n",
    "                        pred_seq.append(bieos_id2label[preds[i][j]])\n",
    "                        true_seq.append(bieos_id2label[bieos_lbl[i][j].item()])\n",
    "                all_preds.append(pred_seq)\n",
    "                all_true.append(true_seq)\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    f1 = seq_f1_score(all_true, all_preds)\n",
    "    return avg_loss, f1, all_true, all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Optimizer: different LR for BERT vs task heads\nbert_params = [(n, p) for n, p in model.bert.named_parameters() if p.requires_grad]\nhead_params = [(n, p) for n, p in model.named_parameters() if not n.startswith('bert') and p.requires_grad]\n\ntotal_training_epochs = PHASE1_EPOCHS + NUM_EPOCHS\ntotal_steps = (len(train_loader) // GRADIENT_ACCUMULATION) * total_training_epochs\nwarmup_steps = int(total_steps * WARMUP_RATIO)\n\noptimizer = torch.optim.AdamW([\n    {'params': [p for _, p in bert_params], 'lr': LR_BERT},\n    {'params': [p for _, p in head_params], 'lr': LR_HEAD},\n], weight_decay=WEIGHT_DECAY)\n\nscheduler = get_linear_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n\nprint(f'Trainable BERT params: {len(bert_params)} tensors')\nprint(f'Trainable Head params: {len(head_params)} tensors')\nprint(f'Total steps (P1+P2) : {total_steps}')\nprint(f'Warmup steps        : {warmup_steps}')\n\n# Training history\nhistory = {'train_loss': [], 'val_loss': [], 'val_f1': [],\n           'loss_ate': [], 'loss_sld': [], 'loss_asd': [], 'loss_crf': []}\n\ndef train_one_epoch(model, train_loader, optimizer, scheduler, device, epoch_str):\n    model.train()\n    epoch_loss = 0\n    epoch_comp = {'ate': 0, 'sld': 0, 'asd': 0, 'crf': 0}\n    optimizer.zero_grad()\n    t0 = time.time()\n\n    step_bar = tqdm(train_loader, desc=epoch_str, leave=False, unit='batch')\n    for step, batch in enumerate(step_bar):\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(**batch)\n        loss = outputs['loss'] / GRADIENT_ACCUMULATION\n        loss.backward()\n\n        if (step + 1) % GRADIENT_ACCUMULATION == 0 or (step + 1) == len(train_loader):\n            torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n            optimizer.step()\n            scheduler.step()\n            optimizer.zero_grad()\n\n        epoch_loss += outputs['loss'].item()\n        for k in epoch_comp:\n            epoch_comp[k] += outputs['losses'][k].item()\n        step_bar.set_postfix(loss=f\"{epoch_loss/(step+1):.3f}\")\n\n    n = len(train_loader)\n    return epoch_loss / n, {k: v / n for k, v in epoch_comp.items()}, time.time() - t0\n\n# =============================================\n# PHASE 1: Pre-training (for Sentiment Connection)\n# =============================================\nprint('=' * 60)\nprint(f'PHASE 1: Pre-training ({PHASE1_EPOCHS} epochs)')\nprint('=' * 60)\n\nfor epoch in range(PHASE1_EPOCHS):\n    avg_train, comp, elapsed = train_one_epoch(\n        model, train_loader, optimizer, scheduler, device,\n        f'P1 Epoch {epoch+1}/{PHASE1_EPOCHS}')\n\n    val_loss, val_f1, _, _ = evaluate(model, val_loader, device, desc='Validating')\n\n    history['train_loss'].append(avg_train)\n    history['val_loss'].append(val_loss)\n    history['val_f1'].append(val_f1)\n    for k in comp:\n        history[f'loss_{k}'].append(comp[k])\n\n    tqdm.write(\n        f'P1 Epoch {epoch+1}/{PHASE1_EPOCHS} | {elapsed:.0f}s | '\n        f'Train: {avg_train:.4f} | Val: {val_loss:.4f} | F1: {val_f1:.4f}\\n'\n        f'  ATE:{comp[\"ate\"]:.3f}  SLD:{comp[\"sld\"]:.3f}  '\n        f'ASD:{comp[\"asd\"]:.3f}  CRF:{comp[\"crf\"]:.3f}')\n\n# =============================================\n# SENTIMENT CONNECTION: Copy SLD → ASD\n# =============================================\nprint('\\n' + '=' * 60)\nprint('Applying Sentiment Connection')\nprint('=' * 60)\nmodel.apply_sentiment_connection()\n\n# =============================================\n# PHASE 2: Main Training (with Early Stopping)\n# =============================================\nprint('\\n' + '=' * 60)\nprint(f'PHASE 2: Main Training (max {NUM_EPOCHS} epochs, patience={EARLY_STOP_PATIENCE})')\nprint('=' * 60)\n\nbest_f1 = 0\npatience_counter = 0\n\nfor epoch in range(NUM_EPOCHS):\n    global_epoch = PHASE1_EPOCHS + epoch + 1\n\n    avg_train, comp, elapsed = train_one_epoch(\n        model, train_loader, optimizer, scheduler, device,\n        f'Epoch {global_epoch}/{PHASE1_EPOCHS + NUM_EPOCHS}')\n\n    val_loss, val_f1, _, _ = evaluate(model, val_loader, device, desc='Validating')\n\n    history['train_loss'].append(avg_train)\n    history['val_loss'].append(val_loss)\n    history['val_f1'].append(val_f1)\n    for k in comp:\n        history[f'loss_{k}'].append(comp[k])\n\n    improved = val_f1 > best_f1\n    if improved:\n        best_f1 = val_f1\n        patience_counter = 0\n        torch.save(model.state_dict(), os.path.join(MODEL_DIR, 'best_model_v3.pt'))\n    else:\n        patience_counter += 1\n\n    tqdm.write(\n        f'Epoch {global_epoch:2d}/{PHASE1_EPOCHS + NUM_EPOCHS} | {elapsed:.0f}s | '\n        f'Train: {avg_train:.4f} | Val: {val_loss:.4f} | '\n        f'F1: {val_f1:.4f} {\"*\" if improved else \"\"} | '\n        f'Patience: {patience_counter}/{EARLY_STOP_PATIENCE}\\n'\n        f'  ATE:{comp[\"ate\"]:.3f}  SLD:{comp[\"sld\"]:.3f}  '\n        f'ASD:{comp[\"asd\"]:.3f}  CRF:{comp[\"crf\"]:.3f}')\n\n    if patience_counter >= EARLY_STOP_PATIENCE:\n        tqdm.write(f'\\nEarly stopping at epoch {global_epoch}')\n        break\n\nactual_epochs = len(history['train_loss'])\nprint(f'\\nTraining finished after {actual_epochs} epochs')\nprint(f'  Phase 1: {PHASE1_EPOCHS} epochs (SLD pre-training)')\nprint(f'  Phase 2: {actual_epochs - PHASE1_EPOCHS} epochs (main training)')\nprint(f'Best Val F1: {best_f1:.4f}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. VISUALISASI TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig, axes = plt.subplots(1, 3, figsize=(16, 4.5))\n\nepochs_range = range(1, len(history['train_loss']) + 1)\n\n# Loss curves\naxes[0].plot(epochs_range, history['train_loss'], label='Train', linewidth=2)\naxes[0].plot(epochs_range, history['val_loss'], label='Val', linewidth=2)\naxes[0].axvline(PHASE1_EPOCHS + 0.5, color='gray', linestyle=':', alpha=0.7, label='Sent. Connection')\naxes[0].set_title('Total Loss', fontweight='bold')\naxes[0].set_xlabel('Epoch'); axes[0].set_ylabel('Loss')\naxes[0].legend()\n\n# F1 curve\naxes[1].plot(epochs_range, history['val_f1'], color='#2ecc71', linewidth=2, marker='o', markersize=4)\nbest_epoch = history['val_f1'].index(max(history['val_f1'])) + 1\naxes[1].axvline(best_epoch, color='#e74c3c', linestyle='--', alpha=0.5,\n                label=f'Best: {max(history[\"val_f1\"]):.4f} (epoch {best_epoch})')\naxes[1].axvline(PHASE1_EPOCHS + 0.5, color='gray', linestyle=':', alpha=0.7, label='Sent. Connection')\naxes[1].set_title('Validation F1 (Entity-level)', fontweight='bold')\naxes[1].set_xlabel('Epoch'); axes[1].set_ylabel('F1')\naxes[1].legend()\n\n# Per-task loss\nfor task in ['ate', 'sld', 'asd', 'crf']:\n    axes[2].plot(epochs_range, history[f'loss_{task}'], label=task.upper(), linewidth=1.5)\naxes[2].axvline(PHASE1_EPOCHS + 0.5, color='gray', linestyle=':', alpha=0.7, label='Sent. Connection')\naxes[2].set_title('Per-Task Loss (Train)', fontweight='bold')\naxes[2].set_xlabel('Epoch'); axes[2].set_ylabel('Loss')\naxes[2].legend()\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. EVALUASI FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(MODEL_DIR, 'best_model_v3.pt'), weights_only=True))\n",
    "val_loss, val_f1, all_true, all_preds = evaluate(model, val_loader, device)\n",
    "\n",
    "print(f'Best Model - Val Loss: {val_loss:.4f}, Val F1: {val_f1:.4f}')\n",
    "print(f'\\n{classification_report(all_true, all_preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. PERBANDINGAN v1 vs v2 vs v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previous checkpoints for comparison\n",
    "v1_path = os.path.join(MODEL_DIR, 'checkpoint_final.pt')\n",
    "v2_path = os.path.join(MODEL_DIR, 'checkpoint_v2.pt')\n",
    "\n",
    "comparisons = {}\n",
    "if os.path.exists(v1_path):\n",
    "    v1 = torch.load(v1_path, weights_only=False, map_location='cpu')\n",
    "    comparisons['v1'] = v1\n",
    "if os.path.exists(v2_path):\n",
    "    v2 = torch.load(v2_path, weights_only=False, map_location='cpu')\n",
    "    comparisons['v2'] = v2\n",
    "\n",
    "if comparisons:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    colors = {'v1': ('#3498db', '--'), 'v2': ('#e74c3c', '--'), 'v3': ('#2ecc71', '-')}\n",
    "\n",
    "    # Loss comparison\n",
    "    for name, ckpt in comparisons.items():\n",
    "        h = ckpt['history']\n",
    "        ep = range(1, len(h['val_loss']) + 1)\n",
    "        color, style = colors[name]\n",
    "        axes[0].plot(ep, h['val_loss'], style, label=f'{name} Val', color=color, alpha=0.7)\n",
    "\n",
    "    v3_ep = range(1, len(history['val_loss']) + 1)\n",
    "    axes[0].plot(v3_ep, history['val_loss'], '-', label='v3 Val', color='#2ecc71', linewidth=2)\n",
    "    axes[0].set_title('Validation Loss: v1 vs v2 vs v3', fontweight='bold')\n",
    "    axes[0].set_xlabel('Epoch'); axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "\n",
    "    # F1 comparison\n",
    "    for name, ckpt in comparisons.items():\n",
    "        h = ckpt['history']\n",
    "        ep = range(1, len(h['val_f1']) + 1)\n",
    "        color, style = colors[name]\n",
    "        axes[1].plot(ep, h['val_f1'], style + 'o', label=f'{name} (best={ckpt[\"best_f1\"]:.4f})',\n",
    "                     color=color, alpha=0.7, markersize=3)\n",
    "\n",
    "    axes[1].plot(v3_ep, history['val_f1'], '-o', label=f'v3 (best={best_f1:.4f})',\n",
    "                 color='#2ecc71', linewidth=2, markersize=3)\n",
    "    axes[1].set_title('Val F1: v1 vs v2 vs v3', fontweight='bold')\n",
    "    axes[1].set_xlabel('Epoch'); axes[1].set_ylabel('F1')\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Summary table\n",
    "    print(f'\\n{\"Metric\":<20} {\"v1 (Baseline)\":>15} {\"v2 (Hyp.Tune)\":>15} {\"v3 (Augmented)\":>15}')\n",
    "    print('=' * 67)\n",
    "    for name, ckpt in comparisons.items():\n",
    "        pass  # Just for reference\n",
    "    v1_f1 = comparisons.get('v1', {}).get('best_f1', '-')\n",
    "    v2_f1 = comparisons.get('v2', {}).get('best_f1', '-')\n",
    "    print(f'{\"Best Val F1\":<20} {v1_f1:>15.4f} {v2_f1:>15.4f} {best_f1:>15.4f}')\n",
    "\n",
    "    v1_ep = len(comparisons.get('v1', {}).get('history', {}).get('train_loss', []))\n",
    "    v2_ep = len(comparisons.get('v2', {}).get('history', {}).get('train_loss', []))\n",
    "    v3_ep = len(history['train_loss'])\n",
    "    print(f'{\"Epochs trained\":<20} {v1_ep:>15} {v2_ep:>15} {v3_ep:>15}')\n",
    "    print(f'{\"Data size\":<20} {\"2,451\":>15} {\"2,451\":>15} {len(raw_data):>15,}')\n",
    "else:\n",
    "    print('Previous checkpoints not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. SIMPAN MODEL & CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "checkpoint = {\n    'model_state_dict': model.state_dict(),\n    'model_name': MODEL_NAME,\n    'max_length': MAX_LENGTH,\n    'proj_dim': PROJ_DIM,\n    'dropout': DROPOUT,\n    'freeze_layers': FREEZE_LAYERS,\n    'bieos_label2id': bieos_label2id,\n    'bieos_id2label': bieos_id2label,\n    'ate_labels': ate_labels,\n    'sld_labels': sld_labels,\n    'asd_labels': asd_labels,\n    'best_f1': best_f1,\n    'history': history,\n    'early_stopped_epoch': len(history['train_loss']),\n    'data_source': 'augmented',\n    'data_size': len(raw_data),\n    'config': {\n        'architecture': 'Paper-aligned (cross-attention, prior embedding, sentiment connection)',\n        'dropout': DROPOUT,\n        'weight_decay': WEIGHT_DECAY,\n        'freeze_layers': f'{FREEZE_LAYERS}/24',\n        'early_stopping': f'patience={EARLY_STOP_PATIENCE}',\n        'asd_class_weights': 'inverse frequency',\n        'augmentation': 'NEG x3, NEU x2 + O-token perturbation',\n        'lambda1': LAMBDA1,\n        'lambda2': LAMBDA2,\n        'phase1_epochs': PHASE1_EPOCHS,\n        'max_relative_position': MAX_REL_POS,\n    }\n}\n\nsave_path = os.path.join(MODEL_DIR, 'checkpoint_v3.pt')\ntorch.save(checkpoint, save_path)\n\nfile_size = os.path.getsize(save_path) / (1024**2)\nprint(f'Checkpoint saved: {save_path}')\nprint(f'File size: {file_size:.1f} MB')\nprint(f'Best F1: {best_f1:.4f}')\nprint(f'Stopped at epoch: {len(history[\"train_loss\"])}')\nprint(f'  Phase 1: {PHASE1_EPOCHS} epochs')\nprint(f'  Phase 2: {len(history[\"train_loss\"]) - PHASE1_EPOCHS} epochs')"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}